{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/tmp/data/mnist/tmpbjd0WU/train_shuffled-00000-of-00001.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [filename]\n",
    "raw_dataset = tf.data.TFRecordDataset(filenames, compression_type='GZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_DESCRIPTION = {\n",
    "    'image': tf.FixedLenFeature([], tf.string, default_value=''),\n",
    "    'label': tf.FixedLenFeature([], tf.int64, default_value=0),\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    # Parse the input tf.Example proto using the dictionary above.\n",
    "    return tf.parse_single_example(example_proto, FEATURE_DESCRIPTION)\n",
    "\n",
    "parsed_dataset = raw_dataset.map(_parse_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = parsed_dataset.make_one_shot_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert byte string tensor to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'get_next'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-64e0b7ab439a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_one_shot_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'get_next'"
     ]
    }
   ],
   "source": [
    "IMAGE_KEY = 'image'\n",
    "LABEL_KEY = 'label'\n",
    "IMAGE_PIXELS = 784\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "with tf.Session():\n",
    "    record = parsed_dataset.make_one_shot_iterator.get_next()\n",
    "\n",
    "features = record\n",
    "\n",
    "image = tf.decode_raw(features[IMAGE_KEY], tf.uint8)\n",
    "image.set_shape((IMAGE_PIXELS))  # 784\n",
    "\n",
    "# Convert label from a scalar uint8 tensor to an int32 scalar.\n",
    "label = tf.cast(features[LABEL_KEY], tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = WIDTH = 28\n",
    "image = tf.reshape(image, (HEIGHT, WIDTH))\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.aaron_simple_example import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/k5/bp3zwqms0bx9sp3p4mfl4vf80000gn/T/tmp6RxoTI\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11ecc1fd0>, '_model_dir': '/var/folders/k5/bp3zwqms0bx9sp3p4mfl4vf80000gn/T/tmp6RxoTI', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 190515 06:54:56 <ipython-input-16-514c55182642>:33] train_steps: 4687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/aaron/Documents/github/transform/venv/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /Users/aaron/Documents/github/transform/venv/lib/python2.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/aaron/Documents/github/transform/venv/lib/python2.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/k5/bp3zwqms0bx9sp3p4mfl4vf80000gn/T/tmp6RxoTI/model.ckpt.\n",
      "INFO:tensorflow:loss = 23.215216, step = 1\n",
      "INFO:tensorflow:global_step/sec: 113.311\n",
      "INFO:tensorflow:loss = 7.984793, step = 101 (0.884 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.904\n",
      "INFO:tensorflow:loss = 4.057125, step = 201 (0.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.279\n",
      "INFO:tensorflow:loss = 1.3891311, step = 301 (0.765 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.059\n",
      "INFO:tensorflow:loss = 1.359172, step = 401 (0.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.948\n",
      "INFO:tensorflow:loss = 0.82935524, step = 501 (0.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.599\n",
      "INFO:tensorflow:loss = 0.6332582, step = 601 (0.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.797\n",
      "INFO:tensorflow:loss = 0.6055377, step = 701 (0.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.057\n",
      "INFO:tensorflow:loss = 0.3837378, step = 801 (0.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.529\n",
      "INFO:tensorflow:loss = 0.39941972, step = 901 (0.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.031\n",
      "INFO:tensorflow:loss = 0.09829545, step = 1001 (0.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.457\n",
      "INFO:tensorflow:loss = 1.1963086, step = 1101 (0.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.18\n",
      "INFO:tensorflow:loss = 0.42075142, step = 1201 (0.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.135\n",
      "INFO:tensorflow:loss = 0.628167, step = 1301 (0.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.566\n",
      "INFO:tensorflow:loss = 0.031241417, step = 1401 (0.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.824\n",
      "INFO:tensorflow:loss = 0.014232501, step = 1501 (0.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.189\n",
      "INFO:tensorflow:loss = 0.9708374, step = 1601 (0.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.917\n",
      "INFO:tensorflow:loss = 1.4903597, step = 1701 (0.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.907\n",
      "INFO:tensorflow:loss = 1.055006, step = 1801 (0.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.425\n",
      "INFO:tensorflow:loss = 0.21964589, step = 1901 (0.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.362\n",
      "INFO:tensorflow:loss = 0.28134733, step = 2001 (0.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.945\n",
      "INFO:tensorflow:loss = 0.010782135, step = 2101 (0.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.95\n",
      "INFO:tensorflow:loss = 0.19978926, step = 2201 (0.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.301\n",
      "INFO:tensorflow:loss = 0.1139563, step = 2301 (0.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.63\n",
      "INFO:tensorflow:loss = 0.054338533, step = 2401 (0.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.578\n",
      "INFO:tensorflow:loss = 0.14360285, step = 2501 (0.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.103\n",
      "INFO:tensorflow:loss = 3.4273121, step = 2601 (0.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.438\n",
      "INFO:tensorflow:loss = 0.19131851, step = 2701 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.877\n",
      "INFO:tensorflow:loss = 1.7834251, step = 2801 (0.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.334\n",
      "INFO:tensorflow:loss = 0.16212541, step = 2901 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.829\n",
      "INFO:tensorflow:loss = 0.11293248, step = 3001 (0.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.357\n",
      "INFO:tensorflow:loss = 0.7637016, step = 3101 (0.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.464\n",
      "INFO:tensorflow:loss = 0.04169342, step = 3201 (0.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.665\n",
      "INFO:tensorflow:loss = 0.051124457, step = 3301 (0.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.297\n",
      "INFO:tensorflow:loss = 0.057671107, step = 3401 (0.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.624\n",
      "INFO:tensorflow:loss = 0.0016738523, step = 3501 (0.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.513\n",
      "INFO:tensorflow:loss = 0.09472822, step = 3601 (0.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.433\n",
      "INFO:tensorflow:loss = 2.5122404, step = 3701 (0.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.488\n",
      "INFO:tensorflow:loss = 0.0014336886, step = 3801 (0.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.525\n",
      "INFO:tensorflow:loss = 0.0008130284, step = 3901 (0.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.927\n",
      "INFO:tensorflow:loss = 0.00990867, step = 4001 (0.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.189\n",
      "INFO:tensorflow:loss = 0.0013675871, step = 4101 (0.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.637\n",
      "INFO:tensorflow:loss = 1.9802998, step = 4201 (0.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.869\n",
      "INFO:tensorflow:loss = 0.055105317, step = 4301 (0.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.405\n",
      "INFO:tensorflow:loss = 0.0006723544, step = 4401 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.07\n",
      "INFO:tensorflow:loss = 0.0012700845, step = 4501 (0.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.428\n",
      "INFO:tensorflow:loss = 0.0036406526, step = 4601 (0.673 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4680 into /var/folders/k5/bp3zwqms0bx9sp3p4mfl4vf80000gn/T/tmp6RxoTI/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.037116677.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-15T13:55:34Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /Users/aaron/Documents/github/transform/venv/lib/python2.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/k5/bp3zwqms0bx9sp3p4mfl4vf80000gn/T/tmp6RxoTI/model.ckpt-4680\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1000/10000]\n",
      "INFO:tensorflow:Evaluation [2000/10000]\n",
      "INFO:tensorflow:Evaluation [3000/10000]\n",
      "INFO:tensorflow:Evaluation [4000/10000]\n",
      "INFO:tensorflow:Evaluation [5000/10000]\n",
      "INFO:tensorflow:Evaluation [6000/10000]\n",
      "INFO:tensorflow:Evaluation [7000/10000]\n",
      "INFO:tensorflow:Evaluation [8000/10000]\n",
      "INFO:tensorflow:Evaluation [9000/10000]\n",
      "INFO:tensorflow:Evaluation [10000/10000]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-15-13:55:45\n",
      "INFO:tensorflow:Saving dict for global step 4680: accuracy = 0.4, average_loss = 2.6270869, global_step = 4680, loss = 2.6270869\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4680: /var/folders/k5/bp3zwqms0bx9sp3p4mfl4vf80000gn/T/tmp6RxoTI/model.ckpt-4680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.4,\n",
       " 'average_loss': 2.6270869,\n",
       " 'global_step': 4680,\n",
       " 'loss': 2.6270869}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from logzero import logger\n",
    "\n",
    "TRAIN_NUM_EPOCHS = 10\n",
    "\n",
    "def get_feature_columns():\n",
    "    image_column = tf.feature_column.numeric_column(IMAGE_KEY, shape=[HEIGHT, WIDTH])\n",
    "    return [image_column]\n",
    "\n",
    "def make_input_fn(filename, batch_size):\n",
    "    def input_fn():\n",
    "        dataset = tf.data.TFRecordDataset(\n",
    "            [filename], compression_type='GZIP')\n",
    "        dataset = dataset.map(decode)\n",
    "        dataset = dataset.map(augment)\n",
    "        dataset = dataset.map(normalize)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        steps = NUM_TRAIN_INSTANCES // TRAIN_BATCH_SIZE\n",
    "        dataset = dataset.repeat(TRAIN_NUM_EPOCHS * steps)\n",
    "        image, label = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n",
    "        return {IMAGE_KEY: image}, label\n",
    "    return input_fn\n",
    "\n",
    "estimator = tf.estimator.DNNClassifier(\n",
    "    feature_columns=get_feature_columns(),\n",
    "    hidden_units=[784, 10],\n",
    "    optimizer=tf.train.AdamOptimizer(1e-4),\n",
    "    n_classes=10,\n",
    "    dropout=0.1,\n",
    ")\n",
    "\n",
    "# train\n",
    "train_steps = TRAIN_NUM_EPOCHS * NUM_TRAIN_INSTANCES / TRAIN_BATCH_SIZE\n",
    "logger.info('train_steps: %s', train_steps)\n",
    "\n",
    "estimator.train(\n",
    "    input_fn=make_input_fn(\n",
    "        filename='/tmp/data/mnist/tmpbjd0WU/train_shuffled-00000-of-00001.gz',\n",
    "        batch_size=28\n",
    "    ),\n",
    "    max_steps=train_steps)\n",
    "\n",
    "# eval\n",
    "result = estimator.evaluate(\n",
    "    input_fn=make_input_fn(\n",
    "        filename='/tmp/data/mnist/tmpbjd0WU/test_shuffled-00000-of-00001.gz',\n",
    "        batch_size=1\n",
    "    ),\n",
    "    steps=NUM_TEST_INSTANCES)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 190515 06:55:55 <ipython-input-17-81a3ce16356c>:6] Bad message (TypeError('not all arguments converted during string formatting',)): {'threadName': 'MainThread', 'name': 'logzero_default', 'thread': 140735958913920, 'created': 1557928555.632613, 'process': 7258, 'processName': 'MainProcess', 'args': ('/tmp/mnist-wed/1',), 'module': '<ipython-input-17-81a3ce16356c>', 'filename': '<ipython-input-17-81a3ce16356c>', 'levelno': 20, 'exc_text': None, 'pathname': '<ipython-input-17-81a3ce16356c>', 'lineno': 6, 'msg': 'Exporting trained model to', 'exc_info': None, 'funcName': '<module>', 'relativeCreated': 363698.1189250946, 'levelname': 'INFO', 'msecs': 632.612943649292}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.saved_model.builder_impl.SavedModelBuilder at 0x12119c550>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version = 1\n",
    "export_path = '/tmp/mnist-wed/%s' % version\n",
    "if os.path.exists(export_path):\n",
    "    shutil.rmtree(export_path)\n",
    "\n",
    "logger.info('Exporting trained model to', export_path)\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /tmp/mnist-wed/1/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/mnist-wed/1/saved_model.pb'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serialized_tf_example = tf.placeholder(tf.string, name='tf_example')\n",
    "classification_inputs = tf.saved_model.utils.build_tensor_info(\n",
    "    serialized_tf_example)\n",
    "\n",
    "prediction_classes = tf.placeholder(tf.int32, shape=[10])\n",
    "classification_outputs_classes = tf.saved_model.utils.build_tensor_info(\n",
    "    prediction_classes)\n",
    "\n",
    "prediction_scores = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "classification_outputs_scores = tf.saved_model.utils.build_tensor_info(\n",
    "    prediction_scores)\n",
    "\n",
    "classification_signature = (\n",
    "      tf.saved_model.signature_def_utils.build_signature_def(\n",
    "          inputs={\n",
    "              tf.saved_model.signature_constants.CLASSIFY_INPUTS:\n",
    "                  classification_inputs\n",
    "          },\n",
    "          outputs={\n",
    "              tf.saved_model.signature_constants.CLASSIFY_OUTPUT_CLASSES:\n",
    "                  classification_outputs_classes,\n",
    "              tf.saved_model.signature_constants.CLASSIFY_OUTPUT_SCORES:\n",
    "                  classification_outputs_scores\n",
    "          },\n",
    "          method_name=tf.saved_model.signature_constants.CLASSIFY_METHOD_NAME))\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[HEIGHT, WIDTH])\n",
    "y = tf.placeholder(tf.float32, shape=[10])\n",
    "tensor_info_x = tf.saved_model.utils.build_tensor_info(x)\n",
    "tensor_info_y = tf.saved_model.utils.build_tensor_info(y)\n",
    "\n",
    "prediction_signature = (\n",
    "    tf.saved_model.signature_def_utils.build_signature_def(\n",
    "        inputs={'images': tensor_info_x},\n",
    "        outputs={'scores': tensor_info_y},\n",
    "        method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))\n",
    "\n",
    "builder.add_meta_graph_and_variables(\n",
    "  sess, [tf.saved_model.tag_constants.SERVING],\n",
    "  signature_def_map={\n",
    "      'predict_images':\n",
    "          prediction_signature,\n",
    "      tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n",
    "          classification_signature,\n",
    "  },\n",
    "  main_op=tf.tables_initializer(),\n",
    "  strip_default_attrs=True)\n",
    "\n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test saved model with `tf.serving` and `docker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
